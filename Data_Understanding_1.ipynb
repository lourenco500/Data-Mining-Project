{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2fb5ad",
   "metadata": {},
   "source": [
    "# Data Mining Project - Group XX 2025/2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c97d4",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e437cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "\n",
    "from itertools import product\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#o svg consegue ampliar infinitamente os gráficos sem perder qualidade mas às vezes é mais lento \n",
    "#por isso agora usamos retina\n",
    "\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aed8a5",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a35e2",
   "metadata": {},
   "source": [
    "Import the datasets from csv files using commas as separators of the columns and setting the unique customer identifier as the index of both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f800b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDB = pd.read_csv('DM_AIAI_FlightsDB.csv', sep = \",\", index_col= \"Loyalty#\")\n",
    "customerDB = pd.read_csv('DM_AIAI_CustomerDB.csv', sep = \",\", index_col= \"Loyalty#\")\n",
    "metaData = pd.read_csv('DM_AIAI_Metadata.csv', sep = \";\", header= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b6f94",
   "metadata": {},
   "source": [
    "Remove the 'Unnamed' column referring to a sequential numbering of the rows, as we set the column \"Loyalty#\" as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da13cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Province or State</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Postal code</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>LoyaltyStatus</th>\n",
       "      <th>EnrollmentDateOpening</th>\n",
       "      <th>CancellationDate</th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>EnrollmentType</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loyalty#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480934</th>\n",
       "      <td>Cecilia</td>\n",
       "      <td>Householder</td>\n",
       "      <td>Cecilia Householder</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>43.653225</td>\n",
       "      <td>-79.383186</td>\n",
       "      <td>M2Z 4K1</td>\n",
       "      <td>female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Urban</td>\n",
       "      <td>70146.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>2/15/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3839.14</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549612</th>\n",
       "      <td>Dayle</td>\n",
       "      <td>Menez</td>\n",
       "      <td>Dayle Menez</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>53.544388</td>\n",
       "      <td>-113.490930</td>\n",
       "      <td>T3G 6Y6</td>\n",
       "      <td>male</td>\n",
       "      <td>College</td>\n",
       "      <td>Rural</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Star</td>\n",
       "      <td>3/9/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3839.61</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429460</th>\n",
       "      <td>Necole</td>\n",
       "      <td>Hannon</td>\n",
       "      <td>Necole Hannon</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>49.282730</td>\n",
       "      <td>-123.120740</td>\n",
       "      <td>V6E 3D9</td>\n",
       "      <td>male</td>\n",
       "      <td>College</td>\n",
       "      <td>Urban</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Star</td>\n",
       "      <td>7/14/2017</td>\n",
       "      <td>1/8/2021</td>\n",
       "      <td>3839.75</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608370</th>\n",
       "      <td>Queen</td>\n",
       "      <td>Hagee</td>\n",
       "      <td>Queen Hagee</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>43.653225</td>\n",
       "      <td>-79.383186</td>\n",
       "      <td>P1W 1K4</td>\n",
       "      <td>male</td>\n",
       "      <td>College</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Star</td>\n",
       "      <td>2/17/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3839.75</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530508</th>\n",
       "      <td>Claire</td>\n",
       "      <td>Latting</td>\n",
       "      <td>Claire Latting</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Hull</td>\n",
       "      <td>45.428730</td>\n",
       "      <td>-75.713364</td>\n",
       "      <td>J8Y 3Z5</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>97832.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>10/25/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3842.79</td>\n",
       "      <td>2021 Promotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100012</th>\n",
       "      <td>Ethan</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>Ethan Thompson</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>46.759733</td>\n",
       "      <td>-71.141009</td>\n",
       "      <td>Y0C 7D6</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Star</td>\n",
       "      <td>2/27/2019</td>\n",
       "      <td>2/27/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>Layla</td>\n",
       "      <td>Young</td>\n",
       "      <td>Layla Young</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>53.524829</td>\n",
       "      <td>-113.546357</td>\n",
       "      <td>L3S 9Y3</td>\n",
       "      <td>female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Rural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>9/20/2017</td>\n",
       "      <td>9/20/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100014</th>\n",
       "      <td>Amelia</td>\n",
       "      <td>Bennett</td>\n",
       "      <td>Amelia Bennett</td>\n",
       "      <td>Canada</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>Moncton</td>\n",
       "      <td>46.051866</td>\n",
       "      <td>-64.825428</td>\n",
       "      <td>G2S 2B6</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Rural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>11/28/2020</td>\n",
       "      <td>11/28/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100015</th>\n",
       "      <td>Benjamin</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>Benjamin Wilson</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>46.862970</td>\n",
       "      <td>-71.133444</td>\n",
       "      <td>B1Z 8T3</td>\n",
       "      <td>female</td>\n",
       "      <td>College</td>\n",
       "      <td>Urban</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>4/9/2020</td>\n",
       "      <td>4/9/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100016</th>\n",
       "      <td>Emma</td>\n",
       "      <td>Martin</td>\n",
       "      <td>Emma Martin</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Dawson Creek</td>\n",
       "      <td>55.720562</td>\n",
       "      <td>-120.160090</td>\n",
       "      <td>M4A 1E4</td>\n",
       "      <td>female</td>\n",
       "      <td>Master</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Star</td>\n",
       "      <td>7/21/2020</td>\n",
       "      <td>7/21/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16921 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         First Name    Last Name        Customer Name Country  \\\n",
       "Loyalty#                                                        \n",
       "480934      Cecilia  Householder  Cecilia Householder  Canada   \n",
       "549612        Dayle        Menez          Dayle Menez  Canada   \n",
       "429460       Necole       Hannon        Necole Hannon  Canada   \n",
       "608370        Queen        Hagee          Queen Hagee  Canada   \n",
       "530508       Claire      Latting       Claire Latting  Canada   \n",
       "...             ...          ...                  ...     ...   \n",
       "100012        Ethan     Thompson       Ethan Thompson  Canada   \n",
       "100013        Layla        Young          Layla Young  Canada   \n",
       "100014       Amelia      Bennett       Amelia Bennett  Canada   \n",
       "100015     Benjamin       Wilson      Benjamin Wilson  Canada   \n",
       "100016         Emma       Martin          Emma Martin  Canada   \n",
       "\n",
       "         Province or State          City   Latitude   Longitude Postal code  \\\n",
       "Loyalty#                                                                      \n",
       "480934             Ontario       Toronto  43.653225  -79.383186     M2Z 4K1   \n",
       "549612             Alberta      Edmonton  53.544388 -113.490930     T3G 6Y6   \n",
       "429460    British Columbia     Vancouver  49.282730 -123.120740     V6E 3D9   \n",
       "608370             Ontario       Toronto  43.653225  -79.383186     P1W 1K4   \n",
       "530508              Quebec          Hull  45.428730  -75.713364     J8Y 3Z5   \n",
       "...                    ...           ...        ...         ...         ...   \n",
       "100012              Quebec   Quebec City  46.759733  -71.141009     Y0C 7D6   \n",
       "100013             Alberta      Edmonton  53.524829 -113.546357     L3S 9Y3   \n",
       "100014       New Brunswick       Moncton  46.051866  -64.825428     G2S 2B6   \n",
       "100015              Quebec   Quebec City  46.862970  -71.133444     B1Z 8T3   \n",
       "100016    British Columbia  Dawson Creek  55.720562 -120.160090     M4A 1E4   \n",
       "\n",
       "          Gender Education Location Code   Income Marital Status  \\\n",
       "Loyalty#                                                           \n",
       "480934    female  Bachelor         Urban  70146.0        Married   \n",
       "549612      male   College         Rural      0.0       Divorced   \n",
       "429460      male   College         Urban      0.0         Single   \n",
       "608370      male   College      Suburban      0.0         Single   \n",
       "530508      male  Bachelor      Suburban  97832.0        Married   \n",
       "...          ...       ...           ...      ...            ...   \n",
       "100012      male  Bachelor      Suburban      NaN         Single   \n",
       "100013    female  Bachelor         Rural      NaN        Married   \n",
       "100014      male  Bachelor         Rural      NaN        Married   \n",
       "100015    female   College         Urban      NaN        Married   \n",
       "100016    female    Master      Suburban      NaN         Single   \n",
       "\n",
       "         LoyaltyStatus EnrollmentDateOpening CancellationDate  \\\n",
       "Loyalty#                                                        \n",
       "480934            Star             2/15/2019              NaN   \n",
       "549612            Star              3/9/2019              NaN   \n",
       "429460            Star             7/14/2017         1/8/2021   \n",
       "608370            Star             2/17/2016              NaN   \n",
       "530508            Star            10/25/2017              NaN   \n",
       "...                ...                   ...              ...   \n",
       "100012            Star             2/27/2019        2/27/2019   \n",
       "100013            Star             9/20/2017        9/20/2017   \n",
       "100014            Star            11/28/2020       11/28/2020   \n",
       "100015            Star              4/9/2020         4/9/2020   \n",
       "100016            Star             7/21/2020        7/21/2020   \n",
       "\n",
       "          Customer Lifetime Value  EnrollmentType  \n",
       "Loyalty#                                           \n",
       "480934                    3839.14        Standard  \n",
       "549612                    3839.61        Standard  \n",
       "429460                    3839.75        Standard  \n",
       "608370                    3839.75        Standard  \n",
       "530508                    3842.79  2021 Promotion  \n",
       "...                           ...             ...  \n",
       "100012                        NaN        Standard  \n",
       "100013                        NaN        Standard  \n",
       "100014                        NaN        Standard  \n",
       "100015                        NaN        Standard  \n",
       "100016                        NaN        Standard  \n",
       "\n",
       "[16921 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customerDB = customerDB.iloc[:, 1:]\n",
    "customerDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb809032",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e789c70",
   "metadata": {},
   "source": [
    "**FlightsDB Database Variable Description**\n",
    "- **Loyalty#:**\tUnique customer identifier linking to CustomerDB\n",
    "- **Year:**\tYear of flight activity record\n",
    "- **Month:**\tMonth of flight activity record (1-12)\n",
    "- **YearMonthDate:**\tFirst day of the month for the activity period\n",
    "- **NumFlights:**\tTotal number of flights taken by customer in the month\n",
    "- **NumFlightsWithCompanions:**\tNumber of flights where customer traveled with companions\n",
    "- **DistanceKM:**\tTotal distance traveled in kilometers for the month\n",
    "- **PointsAccumulated:**\tLoyalty points earned by customer during the month\n",
    "- **PointsRedeemed:**\tLoyalty points spent/redeemed by customer during the month\n",
    "- **DollarCostPointsRedeemed:**\tDollar value of points redeemed during the month\n",
    "\n",
    "**CustomerDB Database Variable Description**\n",
    "- **Loyalty#:**  Unique customer identifier for loyalty program members\n",
    "- **First Name:**   Customer's first name\n",
    "- **Last Name:**   Customer's last name \n",
    "- **Customer Name:** Customer's full name (concatenated)\n",
    "- **Country:**\tCustomer's country of residence\n",
    "- **Province or State:**\tCustomer's province or state\n",
    "- **City:**\tCustomer's city of residence\n",
    "- **Latitude:**\tGeographic latitude coordinate of customer location\n",
    "- **Longitude:**\tGeographic longitude coordinate of customer locatio\n",
    "- **Postal code:**\tCustomer's postal/ZIP code\n",
    "- **Gender:**\tCustomer's gender\n",
    "- **Education:**\tCustomer's highest education level (Bachelor, College, etc.)\n",
    "- **Location:** Code\tUrban/Suburban/Rural classification of customer residence\n",
    "- **Income:**\tCustomer's annual income\n",
    "- **Marital Status:**\tCustomer's marital status (Married, Single, Divorced)\n",
    "- **LoyaltyStatus:**\tCurrent tier status in loyalty program (Star > Nova > Aurora)\n",
    "- **EnrollmentDateOpening:**\tDate when customer joined the loyalty program\n",
    "- **CancellationDate:**\tDate when customer left the program\n",
    "- **Customer Lifetime:** Value\tTotal calculated monetary value of customer relationship\n",
    "- **EnrollmentType:**\tMethod of joining loyalty program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5569d",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f03b5e",
   "metadata": {},
   "source": [
    "Define the project's objectives and requirements by translating business goals into data science goals. \n",
    "This involves understanding the business problem, identifying success criteria, determining resource needs, and creating an initial project plan with stages, duration, and costs.\n",
    "\n",
    "Business Success criteria: \n",
    "- “A 5% reduction in churn results in €50k monthly savings.”\n",
    "\n",
    "Data mining Success criteria: \n",
    "- “Model accuracy ≥ 85% on test data.” \n",
    "- “Segments must be interpretable and actionable by marketing.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b037728d",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee0e54",
   "metadata": {},
   "source": [
    "On this section we will inspect the data shape, column names and data types for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c4971",
   "metadata": {},
   "source": [
    "## General Look at the DataSet (FlightsDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035ec954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608436, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a5ae1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>YearMonthDate</th>\n",
       "      <th>NumFlights</th>\n",
       "      <th>NumFlightsWithCompanions</th>\n",
       "      <th>DistanceKM</th>\n",
       "      <th>PointsAccumulated</th>\n",
       "      <th>PointsRedeemed</th>\n",
       "      <th>DollarCostPointsRedeemed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loyalty#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413052</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9384.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464105</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681785</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14745.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185013</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26311.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>3213.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216596</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19275.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486956</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23967.0</td>\n",
       "      <td>2396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247514</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23029.0</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711864</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25995.0</td>\n",
       "      <td>2599.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721372</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30758.0</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762715</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332716</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287254</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13328.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904920</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436971</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23295.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671534</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Year  Month YearMonthDate  NumFlights  NumFlightsWithCompanions  \\\n",
       "Loyalty#                                                                    \n",
       "413052    2021     12     12/1/2021         2.0                       2.0   \n",
       "464105    2021     12     12/1/2021         0.0                       0.0   \n",
       "681785    2021     12     12/1/2021        10.0                       3.0   \n",
       "185013    2021     12     12/1/2021        16.0                       4.0   \n",
       "216596    2021     12     12/1/2021         9.0                       0.0   \n",
       "486956    2021     12     12/1/2021        12.0                       7.0   \n",
       "247514    2021     12     12/1/2021        17.0                       7.0   \n",
       "711864    2021     12     12/1/2021         6.0                       0.0   \n",
       "721372    2021     12     12/1/2021        11.0                       3.0   \n",
       "762715    2021     12     12/1/2021         0.0                       0.0   \n",
       "332716    2021     12     12/1/2021         0.0                       0.0   \n",
       "287254    2021     12     12/1/2021         7.0                       0.0   \n",
       "904920    2021     12     12/1/2021         0.0                       0.0   \n",
       "436971    2021     12     12/1/2021         2.0                       2.0   \n",
       "671534    2021     12     12/1/2021         0.0                       0.0   \n",
       "\n",
       "          DistanceKM  PointsAccumulated  PointsRedeemed  \\\n",
       "Loyalty#                                                  \n",
       "413052        9384.0              938.0             0.0   \n",
       "464105           0.0                0.0             0.0   \n",
       "681785       14745.0             1474.0             0.0   \n",
       "185013       26311.0             2631.0          3213.0   \n",
       "216596       19275.0             1927.0             0.0   \n",
       "486956       23967.0             2396.0             0.0   \n",
       "247514       23029.0             2302.0             0.0   \n",
       "711864       25995.0             2599.0             0.0   \n",
       "721372       30758.0             3075.0             0.0   \n",
       "762715           0.0                0.0             0.0   \n",
       "332716           0.0                0.0             0.0   \n",
       "287254       13328.0             1332.0             0.0   \n",
       "904920           0.0                0.0             0.0   \n",
       "436971       23295.0             2329.0             0.0   \n",
       "671534           0.0                0.0             0.0   \n",
       "\n",
       "          DollarCostPointsRedeemed  \n",
       "Loyalty#                            \n",
       "413052                         0.0  \n",
       "464105                         0.0  \n",
       "681785                         0.0  \n",
       "185013                        32.0  \n",
       "216596                         0.0  \n",
       "486956                         0.0  \n",
       "247514                         0.0  \n",
       "711864                         0.0  \n",
       "721372                         0.0  \n",
       "762715                         0.0  \n",
       "332716                         0.0  \n",
       "287254                         0.0  \n",
       "904920                         0.0  \n",
       "436971                         0.0  \n",
       "671534                         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDB.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65c0347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>YearMonthDate</th>\n",
       "      <th>NumFlights</th>\n",
       "      <th>NumFlightsWithCompanions</th>\n",
       "      <th>DistanceKM</th>\n",
       "      <th>PointsAccumulated</th>\n",
       "      <th>PointsRedeemed</th>\n",
       "      <th>DollarCostPointsRedeemed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loyalty#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999498</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>30283.2</td>\n",
       "      <td>3028.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999513</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999524</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>22572.9</td>\n",
       "      <td>2257.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999550</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18168.3</td>\n",
       "      <td>1816.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999589</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999631</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12262.5</td>\n",
       "      <td>1226.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999731</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999758</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999788</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999891</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999902</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30766.5</td>\n",
       "      <td>3076.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999911</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999940</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>18261.0</td>\n",
       "      <td>1826.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999982</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999986</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>12/1/2019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Year  Month YearMonthDate  NumFlights  NumFlightsWithCompanions  \\\n",
       "Loyalty#                                                                    \n",
       "999498    2019     12     12/1/2019         0.9                       0.9   \n",
       "999513    2019     12     12/1/2019         0.0                       0.0   \n",
       "999524    2019     12     12/1/2019        13.5                       4.5   \n",
       "999550    2019     12     12/1/2019         8.1                       0.0   \n",
       "999589    2019     12     12/1/2019         0.0                       0.0   \n",
       "999631    2019     12     12/1/2019         3.6                       1.8   \n",
       "999731    2019     12     12/1/2019         0.0                       0.0   \n",
       "999758    2019     12     12/1/2019         0.0                       0.0   \n",
       "999788    2019     12     12/1/2019         0.0                       0.0   \n",
       "999891    2019     12     12/1/2019         0.0                       0.0   \n",
       "999902    2019     12     12/1/2019         7.2                       0.0   \n",
       "999911    2019     12     12/1/2019         0.0                       0.0   \n",
       "999940    2019     12     12/1/2019        14.4                       0.9   \n",
       "999982    2019     12     12/1/2019         0.0                       0.0   \n",
       "999986    2019     12     12/1/2019         0.0                       0.0   \n",
       "\n",
       "          DistanceKM  PointsAccumulated  PointsRedeemed  \\\n",
       "Loyalty#                                                  \n",
       "999498       30283.2            3028.32             0.0   \n",
       "999513           0.0               0.00             0.0   \n",
       "999524       22572.9            2257.29             0.0   \n",
       "999550       18168.3            1816.83             0.0   \n",
       "999589           0.0               0.00             0.0   \n",
       "999631       12262.5            1226.25             0.0   \n",
       "999731           0.0               0.00             0.0   \n",
       "999758           0.0               0.00             0.0   \n",
       "999788           0.0               0.00             0.0   \n",
       "999891           0.0               0.00             0.0   \n",
       "999902       30766.5            3076.65             0.0   \n",
       "999911           0.0               0.00             0.0   \n",
       "999940       18261.0            1826.10             0.0   \n",
       "999982           0.0               0.00             0.0   \n",
       "999986           0.0               0.00             0.0   \n",
       "\n",
       "          DollarCostPointsRedeemed  \n",
       "Loyalty#                            \n",
       "999498                         0.0  \n",
       "999513                         0.0  \n",
       "999524                         0.0  \n",
       "999550                         0.0  \n",
       "999589                         0.0  \n",
       "999631                         0.0  \n",
       "999731                         0.0  \n",
       "999758                         0.0  \n",
       "999788                         0.0  \n",
       "999891                         0.0  \n",
       "999902                         0.0  \n",
       "999911                         0.0  \n",
       "999940                         0.0  \n",
       "999982                         0.0  \n",
       "999986                         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDB.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e78c01",
   "metadata": {},
   "source": [
    "From the visualization of the head and tail of the data base we can already understand that some errors exist:\n",
    "\n",
    "    - NumFlights and NumFlightsWithCompanions as floats...\n",
    "    - PointsAccumulated and PointsRedeemed as floats. Should they be integers?\n",
    "We will further analyse this using describe and info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17515166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 608436 entries, 413052 to 999986\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Year                      608436 non-null  int64  \n",
      " 1   Month                     608436 non-null  int64  \n",
      " 2   YearMonthDate             608436 non-null  object \n",
      " 3   NumFlights                608436 non-null  float64\n",
      " 4   NumFlightsWithCompanions  608436 non-null  float64\n",
      " 5   DistanceKM                608436 non-null  float64\n",
      " 6   PointsAccumulated         608436 non-null  float64\n",
      " 7   PointsRedeemed            608436 non-null  float64\n",
      " 8   DollarCostPointsRedeemed  608436 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 46.4+ MB\n"
     ]
    }
   ],
   "source": [
    "flightsDB.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b848d34",
   "metadata": {},
   "source": [
    "From info we can see that:\n",
    "\n",
    "    - NumFlights and NumFlightsWithCompanions as floats...\n",
    "    - PointsAccumulated and PointsRedeemed as floats. Should they be integers? \n",
    "    - There aren't missing values\n",
    "\n",
    "What will we do?\n",
    "\n",
    "    Analyse with describe to have a different view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To confirm that missing values don't exist\n",
    "flightsDB.replace(\"\", np.nan, inplace=True)\n",
    "flightsDB.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDB.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebc58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDB.describe(include='object')\n",
    "\n",
    "#o \"top\" é a moda e \"freq\" é a frequencia do valor mais frequente\n",
    "#\"unique\" é a quantidade de valores unicos ((36 datas diferentes pq é o primeiro dia de cada mês durante 3 anos))\n",
    "#\"count\" é o numero de valores nao nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d5a0e",
   "metadata": {},
   "source": [
    "From both numeric and categorical describe we don't notice any weird value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c958a90",
   "metadata": {},
   "source": [
    "## Data Exploration and Analysis (FlightDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858810cf",
   "metadata": {},
   "source": [
    "### Unique, Max, Min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34328d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flightsDB[\"Year\"].unique())\n",
    "print(flightsDB[\"Month\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171cfa4",
   "metadata": {},
   "source": [
    "From the code above we can see that our dataset have only values from the years of 2019, 2020 and 2021 and have values from all months of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(flightsDB[\"NumFlights\"].max(), flightsDB[\"NumFlights\"].min())\n",
    "#from this we can see that there are some customers with 0 flights in a month and the maximum number of flights is 21 in a month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e31971",
   "metadata": {},
   "source": [
    "### Values Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDB[\"NumFlights\"].value_counts()\n",
    "#it looks like the most common number of flights in a month is 0, meaning that many customers don't fly every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc489c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDB[\"NumFlightsWithCompanions\"].value_counts()\n",
    "#similarly to NumFlights, the most common value is 0 but the maximum number of flights with companions is 9.9 (float?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flightsDB[\"Year\"].value_counts())\n",
    "#we can see that the number of records for each year is equally distributed\n",
    "\n",
    "print('-------------------------------------')\n",
    "\n",
    "print(flightsDB[\"Month\"].value_counts())\n",
    "#we can see that the number of records for each month is equally distributed just like for the years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5f208",
   "metadata": {},
   "source": [
    "### Check Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174feff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many duplicates exist\n",
    "print(flightsDB.duplicated().sum())\n",
    "\n",
    "#check the percentage of duplicates in our DataFrame\n",
    "print(flightsDB.duplicated().sum() / len(flightsDB) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba3cd0",
   "metadata": {},
   "source": [
    "!!!!    The percentage of duplicates ir almost 50%    !!!!\n",
    "\n",
    "Because of this we understand that having Loyalty# as an index can be a wrong approach to check the duplicates so we read again our csv file and assign it to the variable flightsDB with the Loyalty# as a feature to check again the duplicates considering this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDB = pd.read_csv('DM_AIAI_FlightsDB.csv', sep = \",\")\n",
    "flightsDB.duplicated().sum() / len(flightsDB) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ff2c0",
   "metadata": {},
   "source": [
    "From the new calculation we obtain only 0.48% of duplicated which it makes more sense in our problem.\n",
    "\n",
    "With this value we can decide to drop the duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bcdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDB[flightsDB[\"Loyalty#\"] == 263267]\n",
    "#Here we check that there are duplicates for the Loyalty# number 263267\n",
    "#the DataFrame below show us all the Data associated to this Loyalty number and we can see that some rows have the exactly same information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6447d",
   "metadata": {},
   "source": [
    "There are 72 equal rows meaning all 36 unique values (corresponding to 12 months over 3 years) are duplicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8adecf",
   "metadata": {},
   "source": [
    "As said before, to be sure that we are not losing any information, we need to introduce the column \"Loyalty#\" as a feature and not a index. Because of that the code that follows assign the variable FlightsDB to the new variable created that consider \"Loyalty#\" as a feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f8c02",
   "metadata": {},
   "source": [
    "After all the reasoning about the duplicates we decide to drop the duplicates, since they represent a minimal percentage of the total data and such a loss of information will not be significant for the final objective of this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16562a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we drop the duplicates from the DataFrame with index\n",
    "flightsDB.drop_duplicates(inplace= True)\n",
    "\n",
    "# Check that the duplicates were removed\n",
    "flightsDB.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b97b1c",
   "metadata": {},
   "source": [
    "### New Values Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169aee7",
   "metadata": {},
   "source": [
    "After dropping the duplicates we think that's important to verify again the values of each year and month that were to well distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59460769",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flightsDB[\"Year\"].value_counts())\n",
    "\n",
    "print('--------------------------------')\n",
    "\n",
    "print(flightsDB[\"Month\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c983e",
   "metadata": {},
   "source": [
    "It's possible to understand that the values changed but they are still quite similar. It's obvious that the same will happen if we count the values for the NumFlights and NumFlightWithCompanions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63722f2a",
   "metadata": {},
   "source": [
    "### Correlation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774e4ce",
   "metadata": {},
   "source": [
    "This correlation is also an important analysis to be done. However this doesn't make sense for all variables so we create a new DataFrame with only the variables we want to use to check the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = flightsDB[[\"Year\", \"Month\", \"NumFlights\", \"NumFlightsWithCompanions\", \"DistanceKM\", \"PointsAccumulated\", \"PointsRedeemed\", \"DollarCostPointsRedeemed\"]]\n",
    "\n",
    "new.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c2149",
   "metadata": {},
   "source": [
    "From the code before it's difficult to get conclusions. We will visualize this matrix in a easy way of getting conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = new.corr(method=\"pearson\"). round(2)\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,                # hide upper triangle\n",
    "    annot=True,               # show values\n",
    "    cmap=\"coolwarm\",          # divergent color map\n",
    "    center=0,                 # center colormap in 0\n",
    "    linewidths=0.5,           # lines between cells to help visualization\n",
    "    vmin=-1, vmax=1,          # fix scale\n",
    "    square=True               # make cells square-shaped\n",
    ")\n",
    "\n",
    "\n",
    "plt.title(\"Correlation Matrix (Pearson)\", fontsize=14, pad=15)\n",
    "plt.tight_layout() # improve layout by reducing overlaps\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a008202",
   "metadata": {},
   "source": [
    "Now the analysis of the correlation between each two variables it's much more easy. With this we understand that some variables are perfectly correlated, what let us think that maybe we should not consider all variables to go on with the work. \n",
    "\n",
    "PointsRedeemed and DollarCostPointsRedeemed, DistanceKm and Points Accumulated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c3ec6",
   "metadata": {},
   "source": [
    "## General Look at the Data (CustomerDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ffc3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc7907",
   "metadata": {},
   "source": [
    "From the visualization of the head and tail of the data base we can already understand that some errors exist:\n",
    "\n",
    "    - Missing values in some features\n",
    "    - EnrollmentType as \"2021 Promotion\" when it's suppose to be a type\n",
    "We will further analyse this using describe and info.\n",
    "\n",
    "It's also possible to see that some variables are redundante, such as Costumer Name, First Name and Last Name\n",
    "To solve this problem we will uniformize all the values in data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ce71e",
   "metadata": {},
   "source": [
    "From info we can see that:\n",
    "\n",
    "    - missing values in Income, CustomerLifetimeValue, CancellationDate\n",
    "* the missing values in the features Income can make sense in cases where customers do not want to share their personal annual income. Or they may also be input errors. (Depends on interpretation).\n",
    "\n",
    "* We can also believe that it makes sense to have NaN values in “CancellationDate,” as this means that there are customers who have not left the program.\n",
    "\n",
    "* For the “CustomerLifetimeValue” variable, we believe that it does not make sense to have NaN values because even if the customer has no value for the company, their CustomerLifetimeValue will be 0.\n",
    "\n",
    "What will we do?\n",
    "\n",
    "    Analyse with describe to have a different view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To confirm that missing values exist\n",
    "customerDB.replace(\"\", np.nan, inplace=True)\n",
    "customerDB.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66541fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03809f18",
   "metadata": {},
   "source": [
    "From the numerical describe we can see that:\n",
    "\n",
    "    - Once again we have the column Unnamed that has no relevant values\n",
    "\n",
    "From the rest of the infromation we can't find any other problem from the first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69951f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b9e5f",
   "metadata": {},
   "source": [
    "From the object describe we can conclude that:\n",
    "\n",
    "    - there are no repeted Customer Names (count = unique = 16921);\n",
    "    - there's only one Country, Canada\n",
    "    - other things that will be analysed latter if they are relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1062e12e",
   "metadata": {},
   "source": [
    "## Data Exploration and Analysis (CustomerDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573b840",
   "metadata": {},
   "source": [
    "### Unique, Max, Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ca879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customerDB[\"Country\"].unique()) # with this we can see that only one country exists in the data base\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"Education\"].unique())\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"Location Code\"].unique())\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"Marital Status\"].unique())\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"LoyaltyStatus\"].unique())\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"EnrollmentType\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf549d37",
   "metadata": {},
   "source": [
    "From the results above we can see there aren't weird values for the features analysed. We can also verify that all Costumer's reside in Canada but in different areas, because there's diffrent Location Codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af553c0",
   "metadata": {},
   "source": [
    "### Values Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customerDB[\"Postal code\"].value_counts()) \n",
    "#check the frequency of each postal code and we notice that some postal codes are much more common than others\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"Gender\"].value_counts()) \n",
    "#we conclude that man and woman customers are almost equally represented in the data base\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"Education\"].value_counts()) \n",
    "#we can see that most customers have a Bachelor degree and few have a Master's\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"Location Code\"].value_counts()) \n",
    "#the location codes are quite equally distributed\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"Marital Status\"].value_counts()) \n",
    "#most customers are married and only a few are divorced\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"LoyaltyStatus\"].value_counts()) \n",
    "#there are way more Gold members and platinum members are the least common\n",
    "\n",
    "print('-------------------------------------')\n",
    "print(customerDB[\"EnrollmentType\"].value_counts()) \n",
    "# most customers enrolled through a promotion and very few through 2021 promotion, the difference is huge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f4716",
   "metadata": {},
   "source": [
    "#### Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699449b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921f027",
   "metadata": {},
   "source": [
    "Checking the duplicates we verify that we don´t have any.\n",
    "\n",
    "But it's still important to check the duplicates without the names features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB_no_name = customerDB.drop(columns=[\"First Name\", \"Last Name\", \"Customer Name\"])\n",
    "customerDB_no_name.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d3f2cf",
   "metadata": {},
   "source": [
    "The result is the same so we can conclude that there aren't duplicated values in this DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522bb58",
   "metadata": {},
   "source": [
    "Contrary to what we have seen with the Flights dataset, here is not important to consider the values of Loyalty# as a feature. Still, so we can be consistint when analysing our datasets, we will had this column as a feature also to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c05e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB = pd.read_csv('DM_AIAI_CustomerDB.csv', sep = \",\")\n",
    "# code that we also did in the begining because there's a column with the index numbers that is completely unuseful\n",
    "customerDB = customerDB.iloc[:, 1:] \n",
    "\n",
    "# to verify that the Loyalty# is now a feature and not an index anymore\n",
    "customerDB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8f824",
   "metadata": {},
   "source": [
    "### Correlation between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82edb296",
   "metadata": {},
   "source": [
    "As before this correlation is also an important analysis to be done. However this doesn't make sense for all variables so we create a new DataFrame with only the variables we want to use to check the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabda146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the customerDB and select only the relevant columns for correlation analysis\n",
    "new = customerDB.copy()\n",
    "new = new[[\"Latitude\", \"Longitude\", \"Income\", \"Customer Lifetime Value\", \"EnrollmentDateOpening\", \"CancellationDate\"]]\n",
    "\n",
    "# converting date columns to datetime format\n",
    "new['EnrollmentDateOpening'] = pd.to_datetime(new['EnrollmentDateOpening'], format='%m/%d/%Y', errors='coerce')\n",
    "new['CancellationDate'] = pd.to_datetime(new['CancellationDate'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# using the two date columns converted before to create a new column with the customer duration in days\n",
    "new['CustomerDurationDays'] = (new['CancellationDate'] - new['EnrollmentDateOpening']).dt.days\n",
    "\n",
    "# choose the numerical columns for correlation analysis\n",
    "cols = [\"Latitude\", \"Longitude\", \"Income\", \"Customer Lifetime Value\", \"CustomerDurationDays\"]\n",
    "new[cols].corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0cec6",
   "metadata": {},
   "source": [
    "From the code before it's difficult to get conclusions. We will visualize this matrix in a easy way of getting conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = new.corr(method=\"pearson\"). round(2)\n",
    "\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,                # hide upper triangle\n",
    "    annot=True,               # show values\n",
    "    cmap=\"coolwarm\",          # divergent color map\n",
    "    center=0,                 # center colormap in 0\n",
    "    linewidths=0.5,           # lines between cells to help visualization\n",
    "    vmin=-1, vmax=1,          # fix scale\n",
    "    square=True               # make cells square-shaped\n",
    ")\n",
    "\n",
    "\n",
    "plt.title(\"Correlation Matrix (Pearson)\", fontsize=14, pad=15)\n",
    "plt.tight_layout() # improve layout by reducing overlaps\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268a399",
   "metadata": {},
   "source": [
    "Now the analysis of the correlation between each two variables it's much more easy. With this we understand that the variables EnrollmentDateOpening and CustomerDurationDays are correlated, but we don't think that this is a value that lead us to drop one of this variables. The same happen for the variables Latitude and Longitude that have a bigger correlation but maybe not enough to drop one of this variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd2156",
   "metadata": {},
   "source": [
    "## Data Quality Check in both Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7d287",
   "metadata": {},
   "source": [
    "Identificar missing values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fall2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
